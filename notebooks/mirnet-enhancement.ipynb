{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imutils \n!pip install gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/shilu10/MIRNet-TF2.git","metadata":{"execution":{"iopub.status.busy":"2023-06-29T13:32:26.242181Z","iopub.execute_input":"2023-06-29T13:32:26.242569Z","iopub.status.idle":"2023-06-29T13:32:31.531004Z","shell.execute_reply.started":"2023-06-29T13:32:26.242530Z","shell.execute_reply":"2023-06-29T13:32:31.529905Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'MIRNet-TF2'...\nremote: Enumerating objects: 445, done.\u001b[K\nremote: Counting objects: 100% (163/163), done.\u001b[K\nremote: Compressing objects: 100% (118/118), done.\u001b[K\nremote: Total 445 (delta 108), reused 100 (delta 45), pack-reused 282\u001b[K\nReceiving objects: 100% (445/445), 55.86 MiB | 18.42 MiB/s, done.\nResolving deltas: 100% (248/248), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!mv MIRNet-TF2 MIRNet_TF0","metadata":{"execution":{"iopub.status.busy":"2023-06-29T13:32:31.533974Z","iopub.execute_input":"2023-06-29T13:32:31.534590Z","iopub.status.idle":"2023-06-29T13:32:32.475722Z","shell.execute_reply.started":"2023-06-29T13:32:31.534556Z","shell.execute_reply":"2023-06-29T13:32:32.474538Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!mv MIRNet_TF8/SIDD_Small_sRGB_Only MIRNet_TF9","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train_enhancement.py --loss_function=charbonnier --n_epochs=200 --batch_size=10 --num_rrg=2 --num_mrb=2","metadata":{"execution":{"iopub.status.busy":"2023-06-29T13:45:14.011829Z","iopub.execute_input":"2023-06-29T13:45:14.012915Z","iopub.status.idle":"2023-06-29T15:48:15.053549Z","shell.execute_reply.started":"2023-06-29T13:45:14.012848Z","shell.execute_reply":"2023-06-29T15:48:15.052343Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n['lol_dataset/our485/low/10.png', 'lol_dataset/our485/low/100.png', 'lol_dataset/our485/low/101.png', 'lol_dataset/our485/low/102.png']\ning\nEpoch 1/200\n48/48 [==============================] - 234s 1s/step - loss: 0.0903 - psnr_enchancement: 62.2139 - val_loss: 0.0359 - val_psnr_enchancement: 63.9841 - lr: 1.0000e-04\nEpoch 2/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0443 - psnr_enchancement: 63.6986 - val_loss: 0.0422 - val_psnr_enchancement: 62.6225 - lr: 1.0000e-04\nEpoch 3/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0401 - psnr_enchancement: 63.7109 - val_loss: 0.0395 - val_psnr_enchancement: 62.9835 - lr: 1.0000e-04\nEpoch 4/200\n48/48 [==============================] - 48s 993ms/step - loss: 0.0356 - psnr_enchancement: 64.2897 - val_loss: 0.0400 - val_psnr_enchancement: 62.9353 - lr: 1.0000e-04\nEpoch 5/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0400 - psnr_enchancement: 64.1000 - val_loss: 0.0382 - val_psnr_enchancement: 63.2456 - lr: 1.0000e-04\nEpoch 6/200\n48/48 [==============================] - ETA: 0s - loss: 0.0393 - psnr_enchancement: 63.8961\nEpoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n48/48 [==============================] - 48s 991ms/step - loss: 0.0393 - psnr_enchancement: 63.8961 - val_loss: 0.0367 - val_psnr_enchancement: 63.4878 - lr: 1.0000e-04\nEpoch 7/200\n48/48 [==============================] - 48s 995ms/step - loss: 0.0341 - psnr_enchancement: 64.5465 - val_loss: 0.0360 - val_psnr_enchancement: 63.4167 - lr: 5.0000e-05\nEpoch 8/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0346 - psnr_enchancement: 64.5692 - val_loss: 0.0363 - val_psnr_enchancement: 63.6126 - lr: 5.0000e-05\nEpoch 9/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0340 - psnr_enchancement: 64.5643 - val_loss: 0.0379 - val_psnr_enchancement: 63.1533 - lr: 5.0000e-05\nEpoch 10/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0333 - psnr_enchancement: 64.4072 - val_loss: 0.0353 - val_psnr_enchancement: 63.5939 - lr: 5.0000e-05\nEpoch 11/200\n48/48 [==============================] - 53s 1s/step - loss: 0.0315 - psnr_enchancement: 64.7860 - val_loss: 0.0350 - val_psnr_enchancement: 64.0128 - lr: 5.0000e-05\nEpoch 12/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0322 - psnr_enchancement: 64.7703 - val_loss: 0.0322 - val_psnr_enchancement: 64.2911 - lr: 5.0000e-05\nEpoch 13/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0308 - psnr_enchancement: 64.9623 - val_loss: 0.0315 - val_psnr_enchancement: 64.5117 - lr: 5.0000e-05\nEpoch 14/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0286 - psnr_enchancement: 65.3493 - val_loss: 0.0319 - val_psnr_enchancement: 64.5154 - lr: 5.0000e-05\nEpoch 15/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0287 - psnr_enchancement: 65.4250 - val_loss: 0.0285 - val_psnr_enchancement: 65.0733 - lr: 5.0000e-05\nEpoch 16/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0285 - psnr_enchancement: 65.3640 - val_loss: 0.0269 - val_psnr_enchancement: 65.2046 - lr: 5.0000e-05\nEpoch 17/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0265 - psnr_enchancement: 65.8490 - val_loss: 0.0270 - val_psnr_enchancement: 65.2658 - lr: 5.0000e-05\nEpoch 18/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0270 - psnr_enchancement: 65.7193 - val_loss: 0.0265 - val_psnr_enchancement: 65.3679 - lr: 5.0000e-05\nEpoch 19/200\n48/48 [==============================] - 48s 993ms/step - loss: 0.0250 - psnr_enchancement: 65.9176 - val_loss: 0.0261 - val_psnr_enchancement: 65.2857 - lr: 5.0000e-05\nEpoch 20/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0250 - psnr_enchancement: 66.0696 - val_loss: 0.0232 - val_psnr_enchancement: 65.7704 - lr: 5.0000e-05\nEpoch 21/200\n48/48 [==============================] - 48s 991ms/step - loss: 0.0257 - psnr_enchancement: 65.8872 - val_loss: 0.0248 - val_psnr_enchancement: 65.3219 - lr: 5.0000e-05\nEpoch 22/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0244 - psnr_enchancement: 66.2262 - val_loss: 0.0278 - val_psnr_enchancement: 65.0286 - lr: 5.0000e-05\nEpoch 23/200\n48/48 [==============================] - 48s 992ms/step - loss: 0.0247 - psnr_enchancement: 66.0677 - val_loss: 0.0243 - val_psnr_enchancement: 65.4019 - lr: 5.0000e-05\nEpoch 24/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0252 - psnr_enchancement: 66.0800 - val_loss: 0.0214 - val_psnr_enchancement: 65.9048 - lr: 5.0000e-05\nEpoch 25/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0249 - psnr_enchancement: 66.2164 - val_loss: 0.0263 - val_psnr_enchancement: 65.0339 - lr: 5.0000e-05\nEpoch 26/200\n48/48 [==============================] - 48s 997ms/step - loss: 0.0250 - psnr_enchancement: 66.0892 - val_loss: 0.0234 - val_psnr_enchancement: 65.7278 - lr: 5.0000e-05\nEpoch 27/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0233 - psnr_enchancement: 66.4033 - val_loss: 0.0249 - val_psnr_enchancement: 65.0237 - lr: 5.0000e-05\nEpoch 28/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0227 - psnr_enchancement: 66.3681 - val_loss: 0.0252 - val_psnr_enchancement: 65.2653 - lr: 5.0000e-05\nEpoch 29/200\n48/48 [==============================] - ETA: 0s - loss: 0.0230 - psnr_enchancement: 66.3833\nEpoch 29: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n48/48 [==============================] - 49s 1s/step - loss: 0.0230 - psnr_enchancement: 66.3833 - val_loss: 0.0252 - val_psnr_enchancement: 65.4270 - lr: 5.0000e-05\nEpoch 30/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0215 - psnr_enchancement: 66.7178 - val_loss: 0.0198 - val_psnr_enchancement: 66.2682 - lr: 2.5000e-05\nEpoch 31/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0215 - psnr_enchancement: 66.7495 - val_loss: 0.0205 - val_psnr_enchancement: 66.2559 - lr: 2.5000e-05\nEpoch 32/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0207 - psnr_enchancement: 66.7679 - val_loss: 0.0202 - val_psnr_enchancement: 66.3643 - lr: 2.5000e-05\nEpoch 33/200\n48/48 [==============================] - 48s 995ms/step - loss: 0.0214 - psnr_enchancement: 66.7630 - val_loss: 0.0200 - val_psnr_enchancement: 66.2863 - lr: 2.5000e-05\nEpoch 34/200\n48/48 [==============================] - 48s 992ms/step - loss: 0.0216 - psnr_enchancement: 66.6939 - val_loss: 0.0237 - val_psnr_enchancement: 65.8973 - lr: 2.5000e-05\nEpoch 35/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0204 - psnr_enchancement: 66.9083 - val_loss: 0.0203 - val_psnr_enchancement: 66.4053 - lr: 2.5000e-05\nEpoch 36/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0203 - psnr_enchancement: 66.9712 - val_loss: 0.0223 - val_psnr_enchancement: 66.0667 - lr: 2.5000e-05\nEpoch 37/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0208 - psnr_enchancement: 66.8921 - val_loss: 0.0197 - val_psnr_enchancement: 66.5494 - lr: 2.5000e-05\nEpoch 38/200\n48/48 [==============================] - 48s 993ms/step - loss: 0.0209 - psnr_enchancement: 66.9153 - val_loss: 0.0211 - val_psnr_enchancement: 66.2653 - lr: 2.5000e-05\nEpoch 39/200\n48/48 [==============================] - 48s 993ms/step - loss: 0.0196 - psnr_enchancement: 67.0964 - val_loss: 0.0228 - val_psnr_enchancement: 65.9800 - lr: 2.5000e-05\nEpoch 40/200\n48/48 [==============================] - 48s 993ms/step - loss: 0.0197 - psnr_enchancement: 67.1726 - val_loss: 0.0210 - val_psnr_enchancement: 66.3425 - lr: 2.5000e-05\nEpoch 41/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0205 - psnr_enchancement: 66.9032 - val_loss: 0.0226 - val_psnr_enchancement: 65.7360 - lr: 2.5000e-05\nEpoch 42/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0213 - psnr_enchancement: 66.9145 - val_loss: 0.0198 - val_psnr_enchancement: 66.6268 - lr: 2.5000e-05\nEpoch 43/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0194 - psnr_enchancement: 67.1811 - val_loss: 0.0196 - val_psnr_enchancement: 66.5368 - lr: 2.5000e-05\nEpoch 44/200\n48/48 [==============================] - 48s 995ms/step - loss: 0.0206 - psnr_enchancement: 66.9612 - val_loss: 0.0200 - val_psnr_enchancement: 66.6110 - lr: 2.5000e-05\nEpoch 45/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0207 - psnr_enchancement: 67.1133 - val_loss: 0.0194 - val_psnr_enchancement: 66.7957 - lr: 2.5000e-05\nEpoch 46/200\n48/48 [==============================] - 48s 995ms/step - loss: 0.0203 - psnr_enchancement: 67.1234 - val_loss: 0.0213 - val_psnr_enchancement: 66.3960 - lr: 2.5000e-05\nEpoch 47/200\n48/48 [==============================] - 48s 993ms/step - loss: 0.0191 - psnr_enchancement: 67.3388 - val_loss: 0.0202 - val_psnr_enchancement: 66.5742 - lr: 2.5000e-05\nEpoch 48/200\n48/48 [==============================] - 48s 992ms/step - loss: 0.0184 - psnr_enchancement: 67.4790 - val_loss: 0.0202 - val_psnr_enchancement: 66.6144 - lr: 2.5000e-05\nEpoch 49/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0197 - psnr_enchancement: 67.1344 - val_loss: 0.0191 - val_psnr_enchancement: 66.7431 - lr: 2.5000e-05\nEpoch 50/200\n48/48 [==============================] - ETA: 0s - loss: 0.0198 - psnr_enchancement: 67.2085\nEpoch 50: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n48/48 [==============================] - 49s 1s/step - loss: 0.0198 - psnr_enchancement: 67.2085 - val_loss: 0.0195 - val_psnr_enchancement: 66.6287 - lr: 2.5000e-05\nEpoch 51/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0208 - psnr_enchancement: 67.0715 - val_loss: 0.0170 - val_psnr_enchancement: 67.4933 - lr: 1.2500e-05\nEpoch 52/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0181 - psnr_enchancement: 67.5148 - val_loss: 0.0167 - val_psnr_enchancement: 67.3960 - lr: 1.2500e-05\nEpoch 53/200\n48/48 [==============================] - 48s 991ms/step - loss: 0.0176 - psnr_enchancement: 67.5574 - val_loss: 0.0176 - val_psnr_enchancement: 67.2093 - lr: 1.2500e-05\nEpoch 54/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0185 - psnr_enchancement: 67.4205 - val_loss: 0.0172 - val_psnr_enchancement: 67.3540 - lr: 1.2500e-05\nEpoch 55/200\n48/48 [==============================] - 48s 992ms/step - loss: 0.0170 - psnr_enchancement: 67.8092 - val_loss: 0.0167 - val_psnr_enchancement: 67.4394 - lr: 1.2500e-05\nEpoch 56/200\n48/48 [==============================] - ETA: 0s - loss: 0.0200 - psnr_enchancement: 67.1535\nEpoch 56: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n48/48 [==============================] - 49s 1s/step - loss: 0.0200 - psnr_enchancement: 67.1535 - val_loss: 0.0168 - val_psnr_enchancement: 67.4257 - lr: 1.2500e-05\nEpoch 57/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0190 - psnr_enchancement: 67.3737 - val_loss: 0.0165 - val_psnr_enchancement: 67.6645 - lr: 6.2500e-06\nEpoch 58/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0172 - psnr_enchancement: 67.8959 - val_loss: 0.0165 - val_psnr_enchancement: 67.6768 - lr: 6.2500e-06\nEpoch 59/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0179 - psnr_enchancement: 67.5652 - val_loss: 0.0164 - val_psnr_enchancement: 67.7149 - lr: 6.2500e-06\nEpoch 60/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0171 - psnr_enchancement: 67.6722 - val_loss: 0.0164 - val_psnr_enchancement: 67.6507 - lr: 6.2500e-06\nEpoch 61/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0180 - psnr_enchancement: 67.5583 - val_loss: 0.0164 - val_psnr_enchancement: 67.6537 - lr: 6.2500e-06\nEpoch 62/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0178 - psnr_enchancement: 67.7873 - val_loss: 0.0164 - val_psnr_enchancement: 67.7412 - lr: 6.2500e-06\nEpoch 63/200\n48/48 [==============================] - 48s 995ms/step - loss: 0.0169 - psnr_enchancement: 67.8379 - val_loss: 0.0165 - val_psnr_enchancement: 67.6274 - lr: 6.2500e-06\nEpoch 64/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0181 - psnr_enchancement: 67.5151 - val_loss: 0.0164 - val_psnr_enchancement: 67.6978 - lr: 6.2500e-06\nEpoch 65/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0165 - psnr_enchancement: 67.8867 - val_loss: 0.0164 - val_psnr_enchancement: 67.6879 - lr: 6.2500e-06\nEpoch 66/200\n48/48 [==============================] - 48s 993ms/step - loss: 0.0189 - psnr_enchancement: 67.4312 - val_loss: 0.0166 - val_psnr_enchancement: 67.5978 - lr: 6.2500e-06\nEpoch 67/200\n48/48 [==============================] - ETA: 0s - loss: 0.0169 - psnr_enchancement: 67.7678\nEpoch 67: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n48/48 [==============================] - 48s 993ms/step - loss: 0.0169 - psnr_enchancement: 67.7678 - val_loss: 0.0164 - val_psnr_enchancement: 67.6531 - lr: 6.2500e-06\nEpoch 68/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0164 - psnr_enchancement: 67.9556 - val_loss: 0.0161 - val_psnr_enchancement: 67.7480 - lr: 3.1250e-06\nEpoch 69/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0179 - psnr_enchancement: 67.5693 - val_loss: 0.0162 - val_psnr_enchancement: 67.7498 - lr: 3.1250e-06\nEpoch 70/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0174 - psnr_enchancement: 67.7114 - val_loss: 0.0161 - val_psnr_enchancement: 67.7751 - lr: 3.1250e-06\nEpoch 71/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0169 - psnr_enchancement: 67.8924 - val_loss: 0.0160 - val_psnr_enchancement: 67.8013 - lr: 3.1250e-06\nEpoch 72/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0180 - psnr_enchancement: 67.6114 - val_loss: 0.0159 - val_psnr_enchancement: 67.8325 - lr: 3.1250e-06\nEpoch 73/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0175 - psnr_enchancement: 67.6752 - val_loss: 0.0161 - val_psnr_enchancement: 67.8015 - lr: 3.1250e-06\nEpoch 74/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0171 - psnr_enchancement: 67.7151 - val_loss: 0.0160 - val_psnr_enchancement: 67.8353 - lr: 3.1250e-06\nEpoch 75/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0168 - psnr_enchancement: 67.7777 - val_loss: 0.0159 - val_psnr_enchancement: 67.8411 - lr: 3.1250e-06\nEpoch 76/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0166 - psnr_enchancement: 67.9128 - val_loss: 0.0158 - val_psnr_enchancement: 67.8642 - lr: 3.1250e-06\nEpoch 77/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0168 - psnr_enchancement: 67.7946 - val_loss: 0.0158 - val_psnr_enchancement: 67.8911 - lr: 3.1250e-06\nEpoch 78/200\n48/48 [==============================] - 48s 996ms/step - loss: 0.0165 - psnr_enchancement: 67.9256 - val_loss: 0.0157 - val_psnr_enchancement: 67.8882 - lr: 3.1250e-06\nEpoch 79/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0170 - psnr_enchancement: 67.8261 - val_loss: 0.0160 - val_psnr_enchancement: 67.8444 - lr: 3.1250e-06\nEpoch 80/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0173 - psnr_enchancement: 67.8296 - val_loss: 0.0160 - val_psnr_enchancement: 67.8531 - lr: 3.1250e-06\nEpoch 81/200\n48/48 [==============================] - 48s 993ms/step - loss: 0.0169 - psnr_enchancement: 67.8031 - val_loss: 0.0159 - val_psnr_enchancement: 67.8633 - lr: 3.1250e-06\nEpoch 82/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0162 - psnr_enchancement: 68.0888 - val_loss: 0.0156 - val_psnr_enchancement: 67.9146 - lr: 3.1250e-06\nEpoch 83/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0160 - psnr_enchancement: 67.9916 - val_loss: 0.0160 - val_psnr_enchancement: 67.8284 - lr: 3.1250e-06\nEpoch 84/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0159 - psnr_enchancement: 67.9075 - val_loss: 0.0156 - val_psnr_enchancement: 67.8762 - lr: 3.1250e-06\nEpoch 85/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0173 - psnr_enchancement: 67.7871 - val_loss: 0.0155 - val_psnr_enchancement: 67.9200 - lr: 3.1250e-06\nEpoch 86/200\n48/48 [==============================] - 48s 991ms/step - loss: 0.0178 - psnr_enchancement: 67.4930 - val_loss: 0.0159 - val_psnr_enchancement: 67.8408 - lr: 3.1250e-06\nEpoch 87/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0169 - psnr_enchancement: 67.8777 - val_loss: 0.0156 - val_psnr_enchancement: 67.9226 - lr: 3.1250e-06\nEpoch 88/200\n48/48 [==============================] - 51s 1s/step - loss: 0.0159 - psnr_enchancement: 67.9394 - val_loss: 0.0154 - val_psnr_enchancement: 67.9285 - lr: 3.1250e-06\nEpoch 89/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0165 - psnr_enchancement: 67.9251 - val_loss: 0.0157 - val_psnr_enchancement: 67.8466 - lr: 3.1250e-06\nEpoch 90/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0171 - psnr_enchancement: 67.8886 - val_loss: 0.0154 - val_psnr_enchancement: 67.9352 - lr: 3.1250e-06\nEpoch 91/200\n48/48 [==============================] - 48s 996ms/step - loss: 0.0164 - psnr_enchancement: 67.9615 - val_loss: 0.0156 - val_psnr_enchancement: 67.9021 - lr: 3.1250e-06\nEpoch 92/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0172 - psnr_enchancement: 67.7304 - val_loss: 0.0156 - val_psnr_enchancement: 67.9120 - lr: 3.1250e-06\nEpoch 93/200\n48/48 [==============================] - 48s 995ms/step - loss: 0.0167 - psnr_enchancement: 67.8548 - val_loss: 0.0153 - val_psnr_enchancement: 67.9005 - lr: 3.1250e-06\nEpoch 94/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0165 - psnr_enchancement: 67.8747 - val_loss: 0.0154 - val_psnr_enchancement: 67.9139 - lr: 3.1250e-06\nEpoch 95/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0168 - psnr_enchancement: 68.0000 - val_loss: 0.0153 - val_psnr_enchancement: 67.9500 - lr: 3.1250e-06\nEpoch 96/200\n48/48 [==============================] - 48s 991ms/step - loss: 0.0163 - psnr_enchancement: 67.8779 - val_loss: 0.0154 - val_psnr_enchancement: 67.9194 - lr: 3.1250e-06\nEpoch 97/200\n48/48 [==============================] - 48s 995ms/step - loss: 0.0157 - psnr_enchancement: 67.9549 - val_loss: 0.0154 - val_psnr_enchancement: 67.8885 - lr: 3.1250e-06\nEpoch 98/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0177 - psnr_enchancement: 67.5259 - val_loss: 0.0154 - val_psnr_enchancement: 67.9317 - lr: 3.1250e-06\nEpoch 99/200\n48/48 [==============================] - 48s 991ms/step - loss: 0.0168 - psnr_enchancement: 67.8413 - val_loss: 0.0154 - val_psnr_enchancement: 67.9174 - lr: 3.1250e-06\nEpoch 100/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0164 - psnr_enchancement: 67.7834 - val_loss: 0.0150 - val_psnr_enchancement: 67.9893 - lr: 3.1250e-06\nEpoch 101/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0167 - psnr_enchancement: 67.8068 - val_loss: 0.0151 - val_psnr_enchancement: 67.9618 - lr: 3.1250e-06\nEpoch 102/200\n48/48 [==============================] - 48s 989ms/step - loss: 0.0162 - psnr_enchancement: 68.1050 - val_loss: 0.0152 - val_psnr_enchancement: 67.9011 - lr: 3.1250e-06\nEpoch 103/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0165 - psnr_enchancement: 67.8976 - val_loss: 0.0151 - val_psnr_enchancement: 67.9543 - lr: 3.1250e-06\nEpoch 104/200\n48/48 [==============================] - 48s 995ms/step - loss: 0.0162 - psnr_enchancement: 68.0739 - val_loss: 0.0152 - val_psnr_enchancement: 67.9410 - lr: 3.1250e-06\nEpoch 105/200\n48/48 [==============================] - ETA: 0s - loss: 0.0170 - psnr_enchancement: 67.8668\nEpoch 105: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n48/48 [==============================] - 49s 1s/step - loss: 0.0170 - psnr_enchancement: 67.8668 - val_loss: 0.0152 - val_psnr_enchancement: 67.9365 - lr: 3.1250e-06\nEpoch 106/200\n48/48 [==============================] - 52s 1s/step - loss: 0.0160 - psnr_enchancement: 68.0363 - val_loss: 0.0150 - val_psnr_enchancement: 67.9943 - lr: 1.5625e-06\nEpoch 107/200\n31/48 [==================>...........] - ETA: 15s - loss: 0.0178 - psnr_enchancement: 67.6421Epoch 109/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0164 - psnr_enchancement: 67.8041 - val_loss: 0.0150 - val_psnr_enchancement: 67.9932 - lr: 1.5625e-06\nEpoch 110/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0164 - psnr_enchancement: 67.9368 - val_loss: 0.0151 - val_psnr_enchancement: 67.9708 - lr: 1.5625e-06\nEpoch 111/200\n48/48 [==============================] - ETA: 0s - loss: 0.0169 - psnr_enchancement: 67.7898\nEpoch 111: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n48/48 [==============================] - 48s 992ms/step - loss: 0.0169 - psnr_enchancement: 67.7898 - val_loss: 0.0153 - val_psnr_enchancement: 67.9400 - lr: 1.5625e-06\nEpoch 112/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0170 - psnr_enchancement: 67.8727 - val_loss: 0.0152 - val_psnr_enchancement: 67.9406 - lr: 7.8125e-07\nEpoch 113/200\n48/48 [==============================] - 48s 993ms/step - loss: 0.0157 - psnr_enchancement: 68.1635 - val_loss: 0.0151 - val_psnr_enchancement: 67.9614 - lr: 7.8125e-07\nEpoch 114/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0161 - psnr_enchancement: 68.0465 - val_loss: 0.0151 - val_psnr_enchancement: 67.9634 - lr: 7.8125e-07\nEpoch 115/200\n48/48 [==============================] - 49s 1s/step - loss: 0.0165 - psnr_enchancement: 67.9618 - val_loss: 0.0151 - val_psnr_enchancement: 67.9567 - lr: 7.8125e-07\nEpoch 116/200\n48/48 [==============================] - ETA: 0s - loss: 0.0159 - psnr_enchancement: 68.0831\nEpoch 116: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n48/48 [==============================] - 48s 994ms/step - loss: 0.0159 - psnr_enchancement: 68.0831 - val_loss: 0.0152 - val_psnr_enchancement: 67.9433 - lr: 7.8125e-07\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2             ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv2.imread('GT_SRGB_010.PNG').shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install imutils \n!pip install gdown","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown \nimport os \nimport shutil \nfrom imutils import paths \nimport glob \nimport glob \nimport numpy as np \nfrom tensorflow import keras \nimport tensorflow as tf \nfrom tensorflow.keras import *\n\n\nfrom tensorflow import keras \nimport tensorflow as tf \nimport numpy as np \n\n\ndef random_crop(lr_img, hr_img, hr_crop_size=128):\n    lr_crop_size = hr_crop_size\n    lr_img_shape = tf.shape(lr_img)[:2]\n\n    lr_w = tf.random.uniform(shape=(), maxval=lr_img_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n    lr_h = tf.random.uniform(shape=(), maxval=lr_img_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n\n    hr_w = lr_w\n    hr_h = lr_h\n\n    lr_img_cropped = lr_img[lr_h:lr_h + lr_crop_size, lr_w:lr_w + lr_crop_size]\n    hr_img_cropped = hr_img[hr_h:hr_h + hr_crop_size, hr_w:hr_w + hr_crop_size]\n\n    return lr_img_cropped, hr_img_cropped\n\n\ndef random_flip(lr_img, hr_img):\n    rn = tf.random.uniform(shape=(), maxval=1)\n    return tf.cond(rn < 0.5,\n                   lambda: (lr_img, hr_img),\n                   lambda: (tf.image.flip_left_right(lr_img),\n                            tf.image.flip_left_right(hr_img)))\n\n\ndef random_rotate(lr_img, hr_img):\n    rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)\n    return tf.image.rot90(lr_img, rn), tf.image.rot90(hr_img, rn)\n\n\ndef random_crop_sr(lr_img, hr_img, hr_crop_size=96, scale=2):\n    lr_crop_size = hr_crop_size // scale\n    lr_img_shape = tf.shape(lr_img)[:2]\n\n    lr_w = tf.random.uniform(shape=(), maxval=lr_img_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n    lr_h = tf.random.uniform(shape=(), maxval=lr_img_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n\n    hr_w = lr_w * scale\n    hr_h = lr_h * scale\n\n    lr_img_cropped = lr_img[lr_h:lr_h + lr_crop_size, lr_w:lr_w + lr_crop_size]\n    hr_img_cropped = hr_img[hr_h:hr_h + hr_crop_size, hr_w:hr_w + hr_crop_size]\n\n    return lr_img_cropped, hr_img_cropped\n\n\nclass UnsuuportedFileExtension(Exception):\n    def __init__(self, message):\n        self.message = message\n\n        \nclass InitializationErro(Exception):\n    def __init__(self, message):\n        self.message = message\n        \n\nimport gdown \nimport os \nimport shutil \nfrom imutils import paths \nimport glob \nimport glob \nimport numpy as np \nfrom tensorflow import keras \nimport tensorflow as tf \nfrom tensorflow.keras import *\n\n\n\nclass UnsuuportedFileExtension(Exception):\n    def __init__(self, message):\n        self.message = message\n\n        \nclass InitializationErro(Exception):\n    def __init__(self, message):\n        self.message = message\n        \n\nclass SIDDDataLoader:\n    def __init__(self, dname):\n        assert dname in [\"sidd\"], \"given dataset name is not valid, supported datasets are ['lol']\"  \n        #assert type(resize_shape) == int, 'Unknown dtype for resize shape, needed Int' \n        #assert type(batch_size) == int, 'Unknown dtype for batch_size, needed Int' \n        self.dname = dname \n    \n    def __image_files(self):\n        try:\n            with open('SIDD_Small_sRGB_Only/Scene_Instances.txt') as f:\n                instances = f.read()\n\n            instances = instances.split('\\n')\n            path = 'SIDD_Small_sRGB_Only/Data/'\n\n            noisy_images_path = []\n            gt_images_path = []\n\n            for f in instances:\n                images_path = path + f + '/'\n\n                for g in os.listdir(images_path):\n                    image_path = images_path + g\n\n                    if 'NOISY' in image_path:\n                        noisy_images_path.append(image_path)\n                    else:\n                        gt_images_path.append(image_path)\n\n            return noisy_images_path, gt_images_path\n        \n        except Exception as err:\n            return err\n            \n    def __noisy_image_files(self):\n        try:\n            num_train = 150\n            \n            noisy_images_path, _ = self.__image_files()\n            train_noisy_data_path = noisy_images_path[: num_train]\n            val_noisy_data_path = noisy_images_path[num_train+1: ]\n\n            return train_noisy_data_path, val_noisy_data_path\n        \n        except Exception as err:\n            return err\n    \n    def __gt_image_files(self):\n        try:\n            num_train = 150\n            \n            _, gt_images_path = self.__image_files()\n            train_gt_data_path = gt_images_path[: num_train]\n            val_gt_data_path = gt_images_path[num_train+1: ]\n\n            return train_gt_data_path, val_gt_data_path\n        \n        except Exception as err:\n            return err\n    \n    def __train_tf_dataset(self):\n        try: \n            noisy_train_files, _ = self.__noisy_image_files()\n            gt_train_files, _ = self.__gt_image_files()\n            \n            tf_dataset = tf.data.Dataset.from_tensor_slices((noisy_train_files, gt_train_files)) \n            return tf_dataset\n        \n        except Exception as err:\n            return err \n    \n    def __val_tf_dataset(self):\n        try: \n            _, noisy_val_files = self.__noisy_image_files()\n            _, gt_val_files = self.__gt_image_files()\n            tf_dataset = tf.data.Dataset.from_tensor_slices((noisy_val_files, gt_val_files)) \n            return tf_dataset \n        \n        except Exception as err:\n            return err\n    \n    def initialize(self):\n        try: \n            if self.dname == \"sidd\":\n                SIDD_DATA_PATH = 'https://competitions.codalab.org/my/datasets/download/a26784fe-cf33-48c2-b61f-94b299dbc0f2'\n\n                if not os.path.exists('SIDD_Small_sRGB_Only/Data'):\n                    #os.system(f'wget {SIDD_DATA_PATH}')\n                    # https://drive.google.com/file/d/10TC19ND0qeqUCG_mvfhtOjmXkSunYyud/view?usp=sharing\n                    url = \"https://drive.google.com/uc?id=10TC19ND0qeqUCG_mvfhtOjmXkSunYyud\"\n                    gdown.download(url)\n                    os.system(f'unzip -q smartphone-image-denoising-dataset.zip')\n                    os.system(f'rm smartphone-image-denoising-dataset.zip')\n\n                if (os.path.exists(\"smartphone-image-denoising-dataset.zip\") and not os.path.exists(\"SIDD_Small_sRGB_Only/\")):\n                    os.system(f'unzip -q smartphone-image-denoising-dataset.zip')\n                    os.system(f'rm smartphone-image-denoising-dataset.zip')\n                    \n        except Exception as err:\n            print(err, \"rr\")\n            return err \n        \n    def __read_img(self, img_fpath): \n        try: \n            raw = tf.io.read_file(img_fpath)\n            image = tf.image.decode_png(raw, channels=3)\n            image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n            return image\n            \n        except Exception as err:\n            return err\n        \n    def __load_data(self, lr_img_path, hr_img_path):\n        try: \n            lr_img = self.__read_img(lr_img_path)\n            hr_img = self.__read_img(hr_img_path)\n\n            # resizing\n           # lr_img = tf.image.resize(lr_img, (224, 224))\n           # hr_img = tf.image.resize(hr_img, (224, 224))\n\n            return lr_img, hr_img\n        \n        except Exception as err:\n            return err\n    \n    def image_resize(self, lr_img, hr_img):\n        # resizing\n        lr_img = tf.image.resize(lr_img, (128, 128))\n        hr_img = tf.image.resize(hr_img, (128, 128))\n        \n        return lr_img, hr_img\n\n    def __create_tf_dataset(self, tf_ds, batch_size, transform):\n        \n        if transform:\n            tf_ds = tf_ds.map(lambda lr, hr: random_crop(lr, hr), num_parallel_calls=tf.data.AUTOTUNE)\n            tf_ds = tf_ds.map(random_flip, num_parallel_calls=tf.data.AUTOTUNE)\n            tf_ds = tf_ds.map(random_rotate, num_parallel_calls=tf.data.AUTOTUNE)\n            tf_ds = tf_ds.batch(batch_size, drop_remainder=False)\n\n        if not transform:\n            tf_ds = tf_ds.map(lambda lr, hr: self.image_resize(lr, hr), num_parallel_calls=tf.data.AUTOTUNE)\n            tf_ds = tf_ds.batch(1, drop_remainder=False)\n        \n        tf_ds = tf_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n        \n        return tf_ds\n        \n    def get_dataset(self, subset, batch_size, transform=True):\n        assert subset in (\"train\", 'val'), \"unsupported split type\"\n        try:\n            if subset == \"train\":\n                tf_ds = self.__train_tf_dataset()\n                tf_ds = tf_ds.map(self.__load_data, num_parallel_calls=tf.data.AUTOTUNE)\n                tf_ds = self.__create_tf_dataset(tf_ds, batch_size, transform)\n                return tf_ds\n            \n            else:\n                tf_ds = self.__val_tf_dataset()\n                tf_ds = tf_ds.map(self.__load_data, num_parallel_calls=tf.data.AUTOTUNE)\n                tf_ds = self.__create_tf_dataset(tf_ds, batch_size, transform)\n                return tf_ds\n                \n        except Exception as err:\n            print(err)\n            raise InitializationErro('DataLoader, has not been initialize, use .initalize method')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sl = SIDDDataLoader('sidd')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sl.initialize()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_ds = sl.get_dataset(\"train\", 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(t_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in t_ds:\n    print(i[0].shape, i[1].shape)\n    #break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v_ds = sl.get_dataset(\"val\", 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in v_ds:\n    print(i[0].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}