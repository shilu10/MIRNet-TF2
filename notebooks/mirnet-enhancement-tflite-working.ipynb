{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imutils \n!pip install gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/shilu10/MIRNet-TF2.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv MIRNet-TF2 MIRNet_W1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp /kaggle/working/MIRNet_TF0/checkpoint/saved/enchancement/best_model.h5 .","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv MIRNet-TF2 MIRNet_TF0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \n\nmodel = tf.keras.models.load_model(\"best_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv MIRNet_TF8/SIDD_Small_sRGB_Only MIRNet_TF9","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train_enhancement.py --loss_function=charbonnier --n_epochs=200 --batch_size=10 --num_rrg=2 --num_mrb=2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2             ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv2.imread('GT_SRGB_010.PNG').shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install imutils \n!pip install gdown","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown \nimport os \nimport shutil \nfrom imutils import paths \nimport glob \nimport glob \nimport numpy as np \nfrom tensorflow import keras \nimport tensorflow as tf \nfrom tensorflow.keras import *\n\n\nfrom tensorflow import keras \nimport tensorflow as tf \nimport numpy as np \n\n\ndef random_crop(lr_img, hr_img, hr_crop_size=128):\n    lr_crop_size = hr_crop_size\n    lr_img_shape = tf.shape(lr_img)[:2]\n\n    lr_w = tf.random.uniform(shape=(), maxval=lr_img_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n    lr_h = tf.random.uniform(shape=(), maxval=lr_img_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n\n    hr_w = lr_w\n    hr_h = lr_h\n\n    lr_img_cropped = lr_img[lr_h:lr_h + lr_crop_size, lr_w:lr_w + lr_crop_size]\n    hr_img_cropped = hr_img[hr_h:hr_h + hr_crop_size, hr_w:hr_w + hr_crop_size]\n\n    return lr_img_cropped, hr_img_cropped\n\n\ndef random_flip(lr_img, hr_img):\n    rn = tf.random.uniform(shape=(), maxval=1)\n    return tf.cond(rn < 0.5,\n                   lambda: (lr_img, hr_img),\n                   lambda: (tf.image.flip_left_right(lr_img),\n                            tf.image.flip_left_right(hr_img)))\n\n\ndef random_rotate(lr_img, hr_img):\n    rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)\n    return tf.image.rot90(lr_img, rn), tf.image.rot90(hr_img, rn)\n\n\ndef random_crop_sr(lr_img, hr_img, hr_crop_size=96, scale=2):\n    lr_crop_size = hr_crop_size // scale\n    lr_img_shape = tf.shape(lr_img)[:2]\n\n    lr_w = tf.random.uniform(shape=(), maxval=lr_img_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n    lr_h = tf.random.uniform(shape=(), maxval=lr_img_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n\n    hr_w = lr_w * scale\n    hr_h = lr_h * scale\n\n    lr_img_cropped = lr_img[lr_h:lr_h + lr_crop_size, lr_w:lr_w + lr_crop_size]\n    hr_img_cropped = hr_img[hr_h:hr_h + hr_crop_size, hr_w:hr_w + hr_crop_size]\n\n    return lr_img_cropped, hr_img_cropped\n\n\nclass UnsuuportedFileExtension(Exception):\n    def __init__(self, message):\n        self.message = message\n\n        \nclass InitializationErro(Exception):\n    def __init__(self, message):\n        self.message = message\n        \n\nimport gdown \nimport os \nimport shutil \nfrom imutils import paths \nimport glob \nimport glob \nimport numpy as np \nfrom tensorflow import keras \nimport tensorflow as tf \nfrom tensorflow.keras import *\n\n\n\nclass UnsuuportedFileExtension(Exception):\n    def __init__(self, message):\n        self.message = message\n\n        \nclass InitializationErro(Exception):\n    def __init__(self, message):\n        self.message = message\n        \n\nclass SIDDDataLoader:\n    def __init__(self, dname):\n        assert dname in [\"sidd\"], \"given dataset name is not valid, supported datasets are ['lol']\"  \n        #assert type(resize_shape) == int, 'Unknown dtype for resize shape, needed Int' \n        #assert type(batch_size) == int, 'Unknown dtype for batch_size, needed Int' \n        self.dname = dname \n    \n    def __image_files(self):\n        try:\n            with open('SIDD_Small_sRGB_Only/Scene_Instances.txt') as f:\n                instances = f.read()\n\n            instances = instances.split('\\n')\n            path = 'SIDD_Small_sRGB_Only/Data/'\n\n            noisy_images_path = []\n            gt_images_path = []\n\n            for f in instances:\n                images_path = path + f + '/'\n\n                for g in os.listdir(images_path):\n                    image_path = images_path + g\n\n                    if 'NOISY' in image_path:\n                        noisy_images_path.append(image_path)\n                    else:\n                        gt_images_path.append(image_path)\n\n            return noisy_images_path, gt_images_path\n        \n        except Exception as err:\n            return err\n            \n    def __noisy_image_files(self):\n        try:\n            num_train = 150\n            \n            noisy_images_path, _ = self.__image_files()\n            train_noisy_data_path = noisy_images_path[: num_train]\n            val_noisy_data_path = noisy_images_path[num_train+1: ]\n\n            return train_noisy_data_path, val_noisy_data_path\n        \n        except Exception as err:\n            return err\n    \n    def __gt_image_files(self):\n        try:\n            num_train = 150\n            \n            _, gt_images_path = self.__image_files()\n            train_gt_data_path = gt_images_path[: num_train]\n            val_gt_data_path = gt_images_path[num_train+1: ]\n\n            return train_gt_data_path, val_gt_data_path\n        \n        except Exception as err:\n            return err\n    \n    def __train_tf_dataset(self):\n        try: \n            noisy_train_files, _ = self.__noisy_image_files()\n            gt_train_files, _ = self.__gt_image_files()\n            \n            tf_dataset = tf.data.Dataset.from_tensor_slices((noisy_train_files, gt_train_files)) \n            return tf_dataset\n        \n        except Exception as err:\n            return err \n    \n    def __val_tf_dataset(self):\n        try: \n            _, noisy_val_files = self.__noisy_image_files()\n            _, gt_val_files = self.__gt_image_files()\n            tf_dataset = tf.data.Dataset.from_tensor_slices((noisy_val_files, gt_val_files)) \n            return tf_dataset \n        \n        except Exception as err:\n            return err\n    \n    def initialize(self):\n        try: \n            if self.dname == \"sidd\":\n                SIDD_DATA_PATH = 'https://competitions.codalab.org/my/datasets/download/a26784fe-cf33-48c2-b61f-94b299dbc0f2'\n\n                if not os.path.exists('SIDD_Small_sRGB_Only/Data'):\n                    #os.system(f'wget {SIDD_DATA_PATH}')\n                    # https://drive.google.com/file/d/10TC19ND0qeqUCG_mvfhtOjmXkSunYyud/view?usp=sharing\n                    url = \"https://drive.google.com/uc?id=10TC19ND0qeqUCG_mvfhtOjmXkSunYyud\"\n                    gdown.download(url)\n                    os.system(f'unzip -q smartphone-image-denoising-dataset.zip')\n                    os.system(f'rm smartphone-image-denoising-dataset.zip')\n\n                if (os.path.exists(\"smartphone-image-denoising-dataset.zip\") and not os.path.exists(\"SIDD_Small_sRGB_Only/\")):\n                    os.system(f'unzip -q smartphone-image-denoising-dataset.zip')\n                    os.system(f'rm smartphone-image-denoising-dataset.zip')\n                    \n        except Exception as err:\n            print(err, \"rr\")\n            return err \n        \n    def __read_img(self, img_fpath): \n        try: \n            raw = tf.io.read_file(img_fpath)\n            image = tf.image.decode_png(raw, channels=3)\n            image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n            return image\n            \n        except Exception as err:\n            return err\n        \n    def __load_data(self, lr_img_path, hr_img_path):\n        try: \n            lr_img = self.__read_img(lr_img_path)\n            hr_img = self.__read_img(hr_img_path)\n\n            # resizing\n           # lr_img = tf.image.resize(lr_img, (224, 224))\n           # hr_img = tf.image.resize(hr_img, (224, 224))\n\n            return lr_img, hr_img\n        \n        except Exception as err:\n            return err\n    \n    def image_resize(self, lr_img, hr_img):\n        # resizing\n        lr_img = tf.image.resize(lr_img, (128, 128))\n        hr_img = tf.image.resize(hr_img, (128, 128))\n        \n        return lr_img, hr_img\n\n    def __create_tf_dataset(self, tf_ds, batch_size, transform):\n        \n        if transform:\n            tf_ds = tf_ds.map(lambda lr, hr: random_crop(lr, hr), num_parallel_calls=tf.data.AUTOTUNE)\n            tf_ds = tf_ds.map(random_flip, num_parallel_calls=tf.data.AUTOTUNE)\n            tf_ds = tf_ds.map(random_rotate, num_parallel_calls=tf.data.AUTOTUNE)\n            tf_ds = tf_ds.batch(batch_size, drop_remainder=False)\n\n        if not transform:\n            tf_ds = tf_ds.map(lambda lr, hr: self.image_resize(lr, hr), num_parallel_calls=tf.data.AUTOTUNE)\n            tf_ds = tf_ds.batch(1, drop_remainder=False)\n        \n        tf_ds = tf_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n        \n        return tf_ds\n        \n    def get_dataset(self, subset, batch_size, transform=True):\n        assert subset in (\"train\", 'val'), \"unsupported split type\"\n        try:\n            if subset == \"train\":\n                tf_ds = self.__train_tf_dataset()\n                tf_ds = tf_ds.map(self.__load_data, num_parallel_calls=tf.data.AUTOTUNE)\n                tf_ds = self.__create_tf_dataset(tf_ds, batch_size, transform)\n                return tf_ds\n            \n            else:\n                tf_ds = self.__val_tf_dataset()\n                tf_ds = tf_ds.map(self.__load_data, num_parallel_calls=tf.data.AUTOTUNE)\n                tf_ds = self.__create_tf_dataset(tf_ds, batch_size, transform)\n                return tf_ds\n                \n        except Exception as err:\n            print(err)\n            raise InitializationErro('DataLoader, has not been initialize, use .initalize method')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sl = SIDDDataLoader('sidd')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sl.initialize()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_ds = sl.get_dataset(\"train\", 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(t_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in t_ds:\n    print(i[0].shape, i[1].shape)\n    #break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v_ds = sl.get_dataset(\"val\", 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in v_ds:\n    print(i[0].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/shilu10/MIRNet-TF2.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv MIRNet-TF2 MIRNet_enhancement","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!echo \"from .models import get_enhancement_model, get_denoising_model, get_super_resolution_model\" >> __init__.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train_enhancement.py --loss_function=charbonnier --n_epochs=100 --batch_size=5 --num_rrg=2 --num_mrb=2 --use_custom_trainer=False","metadata":{"execution":{"iopub.status.busy":"2023-06-30T14:19:58.315221Z","iopub.execute_input":"2023-06-30T14:19:58.315607Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 717, in _restore_from_tensors\n    assigned_variable = shape_safe_assign_variable_handle(\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 312, in shape_safe_assign_variable_handle\n    shape.assert_is_compatible_with(value_tensor.shape)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py\", line 1359, in assert_is_compatible_with\n    raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\nValueError: Shapes (3,) and (64,) are incompatible\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/kaggle/working/MIRNet_enhancement/train_enhancement.py\", line 140, in <module>\n    train()\n  File \"/kaggle/working/MIRNet_enhancement/train_enhancement.py\", line 110, in train\n    status = checkpoint.restore(manager.latest_checkpoint)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py\", line 2591, in restore\n    status = self.read(save_path, options=options)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py\", line 2463, in read\n    result = self._saver.restore(save_path=save_path, options=options)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py\", line 1452, in restore\n    checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root,\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/restore.py\", line 61, in restore\n    restore_ops = self._restore_descendants(reader)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/restore.py\", line 468, in _restore_descendants\n    current_position.checkpoint.restore_saveables(\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py\", line 359, in restore_saveables\n    registered_savers).restore(self.save_path_tensor, self.options)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/functional_saver.py\", line 499, in restore\n    restore_ops = restore_fn()\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/checkpoint/functional_saver.py\", line 467, in restore_fn\n    ret = restore_fn(restored_tensors)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 821, in _restore_from_tensors\n    return saveable_object_to_restore_fn(self.saveables)(restored_tensors)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 858, in _restore_from_tensors\n    restore_ops[saveable.name] = saveable.restore(\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 688, in restore\n    ret = restore_fn(restored_tensor_dict)\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 720, in _restore_from_tensors\n    raise ValueError(\nValueError: Received incompatible tensor with shape (64,) when attempting to restore variable with shape (3,) and name conv2d_425/bias:0.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"pretrained_weights/super_resolution/best_model.h5\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mirnet import get_enhancement_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_enhancement_model(\n            num_rrg=1,\n            num_mrb=1,\n            num_channels=64\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_keras_model(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tflite_model = converter.convert()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tflite_model_path = \"pretrained_weights/super_resolution/best_model.tflite\"\n\nwith open(tflite_model_path, 'wb') as f:\n    f.write(tflite_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tflite_model_path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inferrer(image, input_dims=(1, 400, 600, 3)):\n    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    interpreter.resize_tensor_input(input_details[0]['index'], input_dims)\n\n    input_index = input_details[0][\"index\"]\n    output_index = output_details[0][\"index\"]\n\n    interpreter.allocate_tensors()\n    interpreter.set_tensor(input_index, image)\n\n    interpreter.invoke()\n    output = interpreter.get_tensor(output_index)\n    \n    # Convert output array to image\n    # output_image = (np.squeeze(output, axis=0).clip(0, 1) * 255).astype(np.uint8)\n\n    # img = Image.fromarray(output_image)\n    \n    return output[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob, time\n\nlowlight_test_images_path = \"test/enhancement/\"\ntest_files = glob.glob(lowlight_test_images_path + \"*.png\")\n\nfor test_file in tqdm.tqdm(test_files, total=len(test_files)):\n    \n        filename = test_file.split(\"/\")[-1]\n        lr_img = cv2.imread(test_file)\n        lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2RGB)\n        \n        # for resizing specific model data to specific dim.\n        lr_img = get_lowres_image(lr_img, mode=\"enhancement\")\n        \n        inputs = img_to_array(lr_img)\n        inputs = np.expand_dims(inputs, axis=0)\n        t = time.time()\n        \n        lr_img_shape = lr_img.shape\n        inferrer_input_dims = (1, lr_img_shape[0], lr_img_shape[1], lr_img_shape[2])\n        enhanced_image = inferrer(inputs, inferrer_input_dims)\n        print(\"Time taken for inference: \", time.time() - t)\n\n        if False:\n            plt.figure()\n            plt.subplot(131)\n            plt.imshow(original_img)\n            \n            plt.subplot(132)\n            plt.imshow(enhanced_image)\n            \n            plt.show()\n        \n        \n        save_file_dir = lowlight_test_images_path.replace('test', 'results')\n        save_file_path = save_file_dir  + filename\n        print(save_file_path, \"save path\")\n        cv2.imwrite(save_file_path, cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2RGB))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_paths = glob.glob(\"results/enhancement/*.png\")\nfor img_path in img_paths:\n#    n_rows = len(img_paths)\n    img = cv2.imread(img_path)\n    \n    print(img.shape, \"result shape\")\n\n    plt.figure()\n    plt.imshow(img)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"4","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tqdm\nimport numpy as np \nimport tensorflow as tf \nimport PIL\nfrom PIL import Image\nimport cv2\nfrom tensorflow.keras.preprocessing.image import img_to_array\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lowres_image(img, mode=\"enhancement\", scale_factor=4):\n    if mode == \"denoise\":\n        img = cv2.resize(img, (512, 360))\n    \n    if mode == \"super_resolution\":\n        img = cv2.resize(img, (400, 260))\n        \n    else:\n        img = img \n    \n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inferrer(image, input_dims=(1, 400, 600, 3)):\n    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    interpreter.resize_tensor_input(input_details[0]['index'], input_dims)\n\n    input_index = input_details[0][\"index\"]\n    output_index = output_details[0][\"index\"]\n\n    interpreter.allocate_tensors()\n    interpreter.set_tensor(input_index, image)\n\n    interpreter.invoke()\n    output = interpreter.get_tensor(output_index)\n    \n    # Convert output array to image\n    # output_image = (np.squeeze(output, axis=0).clip(0, 1) * 255).astype(np.uint8)\n\n    # img = Image.fromarray(output_image)\n    \n    return output[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob, time\n\nlowlight_test_images_path = \"test/enhancement/\"\ntest_files = glob.glob(lowlight_test_images_path + \"*.png\")\n\nfor test_file in tqdm.tqdm(test_files, total=len(test_files)):\n    \n        filename = test_file.split(\"/\")[-1]\n        lr_img = cv2.imread(test_file)\n        lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2RGB)\n        \n        # for resizing specific model data to specific dim.\n        lr_img = get_lowres_image(lr_img, mode=\"enhancement\")\n        \n        inputs = img_to_array(lr_img)\n        inputs = np.expand_dims(inputs, axis=0)\n        t = time.time()\n        \n        lr_img_shape = lr_img.shape\n        inferrer_input_dims = (1, lr_img_shape[0], lr_img_shape[1], lr_img_shape[2])\n        enhanced_image = inferrer(inputs, inferrer_input_dims)\n        print(\"Time taken for inference: \", time.time() - t)\n\n        if False:\n            plt.figure()\n            plt.subplot(131)\n            plt.imshow(original_img)\n            \n            plt.subplot(132)\n            plt.imshow(enhanced_image)\n            \n            plt.show()\n        \n        \n        save_file_dir = lowlight_test_images_path.replace('test', 'results')\n        save_file_path = save_file_dir  + filename\n        print(save_file_path, \"save path\")\n        cv2.imwrite(save_file_path, cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2RGB))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_paths = glob.glob(\"results/enhancement/*.png\")\nfor img_path in img_paths:\n#    n_rows = len(img_paths)\n    img = cv2.imread(img_path)\n    \n    print(img.shape, \"result shape\")\n\n    plt.figure()\n    plt.imshow(img)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gdown \n!pip install imutils ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train_denoise.py --num_rrg=1 --num_mrb=1 --n_epochs=2 --batch_size=5 --use_custom_trainer=True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# enhancement \n# denoise \n# super_resolution\n# tflite.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mirnet import get_denoising_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"denoise = get_denoising_model(num_rrg=2, num_mrb=2, num_channels=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"denoise.load_weights(\"pretrained_weights/denoise/best_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_keras_model(denoise)\ntflite_model = converter.convert()\nwith open(\"pretrained_weights/denoise/best_model.tflite\", 'wb') as f:\n    f.write(tflite_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inferrer(image, input_dims=(1, 400, 600, 3)):\n    interpreter = tf.lite.Interpreter(model_path=\"pretrained_weights/denoise/best_model.tflite\")\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    interpreter.resize_tensor_input(input_details[0]['index'], input_dims)\n\n    input_index = input_details[0][\"index\"]\n    output_index = output_details[0][\"index\"]\n\n    interpreter.allocate_tensors()\n    interpreter.set_tensor(input_index, image)\n\n    interpreter.invoke()\n    output = interpreter.get_tensor(output_index)\n    \n    # Convert output array to image\n    # output_image = (np.squeeze(output, axis=0).clip(0, 1) * 255).astype(np.uint8)\n\n    # img = Image.fromarray(output_image)\n    \n    return output[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob, time\n\nlowlight_test_images_path = \"test/denoise/\"\ntest_files = glob.glob(lowlight_test_images_path + \"*.PNG\")\n\nfor test_file in tqdm.tqdm(test_files, total=len(test_files)):\n    \n        filename = test_file.split(\"/\")[-1]\n        lr_img = cv2.imread(test_file)\n        lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2RGB)\n        print(lr_img.shape)\n        \n        # for resizing specific model data to specific dim.\n        lr_img = get_lowres_image(lr_img, mode=\"denoise\")\n        print(lr_img.shape)\n        \n        inputs = img_to_array(lr_img)\n        inputs = np.expand_dims(inputs, axis=0)\n        t = time.time()\n        \n        lr_img_shape = lr_img.shape\n        inferrer_input_dims = (1, lr_img_shape[0], lr_img_shape[1], lr_img_shape[2])\n        enhanced_image = inferrer(inputs, inferrer_input_dims)\n        print(\"Time taken for inference: \", time.time() - t)\n\n        if False:\n            plt.figure()\n            plt.subplot(131)\n            plt.imshow(original_img)\n            \n            plt.subplot(132)\n            plt.imshow(enhanced_image)\n            \n            plt.show()\n        \n        \n        save_file_dir = lowlight_test_images_path.replace('test', 'results')\n        save_file_path = save_file_dir  + filename\n        print(save_file_path, \"save path\")\n        cv2.imwrite(save_file_path, cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2RGB))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_paths = glob.glob(\"results/denoise/*.PNG\")\nfor img_path in img_paths:\n#    n_rows = len(img_paths)\n    img = cv2.imread(img_path)\n    \n    print(img.shape, \"result shape\")\n\n    plt.figure()\n    plt.imshow(img)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if tflite converted, \n    # we need to test denoise tflite model.\n    # test the code for testin_denoise\n    # test the code for super_resolution\n    # tflite sr.\n    # tssting sr code.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train_super_resolution.py --n_epochs=3 --batch_size=5 --num_rrg=1 --num_mrb=1 --use_custom_trainer=True --loss_function=charbonnier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!echo \"from .models import get_enhancement_model, get_denoising_model, get_super_resolution_model\" >> __init__.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv MIRNet_W/.div2k MIRNet_W1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv /kaggle/working/MIRNet_W/SIDD_Small_sRGB_Only MIRNet_W1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat __init__.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mirnet import get_super_resolution_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Reference: https://github.com/krasserm/super-resolution/blob/master/data.py\nimport gdown \nimport os \nimport shutil \nfrom imutils import paths \nimport glob \nfrom glob import glob \nimport numpy as np \nfrom tensorflow import keras \nimport tensorflow as tf \nfrom tensorflow.keras import *\nfrom tensorflow.python.data.experimental import AUTOTUNE\nfrom dataloaders.utils import random_crop, random_crop_sr, random_flip, random_rotate\n\n\nclass SRDataLoader1:\n    def __init__(self,\n                 scale=2,\n                 subset='train',\n                 downgrade='bicubic',\n                 images_dir='.div2k/images',\n                 caches_dir='.div2k/caches'):\n\n        self._ntire_2018 = True\n\n        _scales = [2, 3, 4, 8]\n\n        if scale in _scales:\n            self.scale = scale\n        else:\n            raise ValueError(f'scale must be in ${_scales}')\n\n        if subset == 'train':\n            self.image_ids = range(1, 801)\n        elif subset == 'valid':\n            self.image_ids = range(801, 901)\n        else:\n            raise ValueError(\"subset must be 'train' or 'valid'\")\n\n        _downgrades_a = ['bicubic', 'unknown']\n        _downgrades_b = ['mild', 'difficult']\n\n        if scale == 8 and downgrade != 'bicubic':\n            raise ValueError(f'scale 8 only allowed for bicubic downgrade')\n\n        if downgrade in _downgrades_b and scale != 4:\n            raise ValueError(f'{downgrade} downgrade requires scale 4')\n\n        if downgrade == 'bicubic' and scale == 8:\n            self.downgrade = 'x8'\n        elif downgrade in _downgrades_b:\n            self.downgrade = downgrade\n        else:\n            self.downgrade = downgrade\n            self._ntire_2018 = False\n\n        self.subset = subset\n        self.images_dir = images_dir\n        self.caches_dir = caches_dir\n\n        os.makedirs(images_dir, exist_ok=True)\n        os.makedirs(caches_dir, exist_ok=True)\n\n    def __len__(self):\n        return len(self.image_ids)\n\n    def dataset(self, batch_size=16, repeat_count=None, random_transform=True):\n        ds = tf.data.Dataset.zip((self.lr_dataset(), self.hr_dataset()))\n        if random_transform:\n            ds = ds.map(lambda lr, hr: random_crop_sr(lr, hr, scale=self.scale), num_parallel_calls=AUTOTUNE)\n            ds = ds.map(random_rotate, num_parallel_calls=AUTOTUNE)\n            ds = ds.map(random_flip, num_parallel_calls=AUTOTUNE)\n            ds = ds.map(lambda lr, hr: (tf.image.convert_image_dtype(lr, tf.float32), tf.image.convert_image_dtype(hr, tf.float32)))\n        \n        if not random_transform:\n            ds = ds.map(lambda lr, hr: random_crop_sr(lr, hr, scale=self.scale), num_parallel_calls=AUTOTUNE)\n      #      ds = ds.map(lambda lr, hr: lr/255.0, hr/255.0)\n            ds = ds.map(lambda lr, hr: (tf.image.convert_image_dtype(lr, tf.float32), tf.image.convert_image_dtype(hr, tf.float32)))\n            \n        ds = ds.batch(batch_size)\n       # ds = ds.repeat(repeat_count)\n        ds = ds.prefetch(buffer_size=AUTOTUNE)\n        return ds\n\n    def hr_dataset(self):\n        if not os.path.exists(self._hr_images_dir()):\n            download_archive(self._hr_images_archive(), self.images_dir, extract=True)\n\n        ds = self._images_dataset(self._hr_image_files()).cache(self._hr_cache_file())\n\n        # creating a cache.\n        # if not os.path.exists(self._hr_cache_index()):\n        #    self._populate_cache(ds, self._hr_cache_file())\n\n        return ds\n\n    def lr_dataset(self):\n        if not os.path.exists(self._lr_images_dir()):\n            download_archive(self._lr_images_archive(), self.images_dir, extract=True)\n\n        ds = self._images_dataset(self._lr_image_files()).cache(self._lr_cache_file())\n\n        # creating a cache.\n        # if not os.path.exists(self._lr_cache_index()):\n        #    self._populate_cache(ds, self._lr_cache_file())\n\n        return ds\n\n    def _hr_cache_file(self):\n        return os.path.join(self.caches_dir, f'DIV2K_{self.subset}_HR.cache')\n\n    def _lr_cache_file(self):\n        return os.path.join(self.caches_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}_X{self.scale}.cache')\n\n    def _hr_cache_index(self):\n        return f'{self._hr_cache_file()}.index'\n\n    def _lr_cache_index(self):\n        return f'{self._lr_cache_file()}.index'\n\n    def _hr_image_files(self):\n        images_dir = self._hr_images_dir()\n        return [os.path.join(images_dir, f'{image_id:04}.png') for image_id in self.image_ids]\n\n    def _lr_image_files(self):\n        images_dir = self._lr_images_dir()\n        return [os.path.join(images_dir, self._lr_image_file(image_id)) for image_id in self.image_ids]\n\n    def _lr_image_file(self, image_id):\n        if not self._ntire_2018 or self.scale == 8:\n            return f'{image_id:04}x{self.scale}.png'\n        else:\n            return f'{image_id:04}x{self.scale}{self.downgrade[0]}.png'\n\n    def _hr_images_dir(self):\n        return os.path.join(self.images_dir, f'DIV2K_{self.subset}_HR')\n\n    def _lr_images_dir(self):\n        if self._ntire_2018:\n            return os.path.join(self.images_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}')\n        else:\n            return os.path.join(self.images_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}', f'X{self.scale}')\n\n    def _hr_images_archive(self):\n        return f'DIV2K_{self.subset}_HR.zip'\n\n    def _lr_images_archive(self):\n        if self._ntire_2018:\n            return f'DIV2K_{self.subset}_LR_{self.downgrade}.zip'\n        else:\n            return f'DIV2K_{self.subset}_LR_{self.downgrade}_X{self.scale}.zip'\n\n    @staticmethod\n    def _images_dataset(image_files):\n        ds = tf.data.Dataset.from_tensor_slices(image_files)\n        ds = ds.map(tf.io.read_file)\n        ds = ds.map(lambda x: tf.image.decode_png(x, channels=3), num_parallel_calls=AUTOTUNE)\n     #   ds = ds.map(lambda x: tf.image.convert_image_dtype(x, dtype=tf.float32))\n        return ds\n\n    @staticmethod\n    def _populate_cache(ds, cache_file):\n        print(f'Caching decoded images in {cache_file} ...')\n        for _ in ds: pass\n        print(f'Cached decoded images in {cache_file}.')\n\n\ndef download_archive(file, target_dir, extract=True):\n    source_url = f'http://data.vision.ee.ethz.ch/cvl/DIV2K/{file}'\n    target_dir = os.path.abspath(target_dir)\n    tf.keras.utils.get_file(file, source_url, cache_subdir=target_dir, extract=extract)\n    os.remove(os.path.join(target_dir, file))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_super_resolution_model(1, 1, 64, 4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = SRDataLoader1(\n            scale=4,            \n            downgrade=\"bicubic\",\n            subset='train'\n        )      \n                         \ntrain_ds = train_loader.dataset(\n            batch_size=10,        \n            random_transform=True, \n        )  \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in train_ds:\n    print(i[0])\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_loader = SRDataLoader1(\n            scale=4,            \n            downgrade=\"bicubic\",\n            subset='valid'\n        )      \n                         \nval_ds = val_loader.dataset(\n            batch_size=1,        # bcoz no transformation is applied, so samples have a different img_size.\n            random_transform=False, \n        )  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import psnr_denoising\n\nearly_stopping_callback = keras.callbacks.EarlyStopping(\n            monitor=\"val_psnr_denoising\",\n            patience=10,\n            mode='max'\n        )\n\nmodel_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n            \"dummy_training\" + \"best_model.h5\",\n            save_weights_only=True,\n            monitor=\"val_psnr_denoising\",\n            mode=\"max\",\n            save_best_only=True,\n            period=1\n        )\n\nreduce_lr_loss = keras.callbacks.ReduceLROnPlateau(\n            monitor='val_psnr_denoising',\n            factor=0.5,\n            patience=5,\n            verbose=1,\n            epsilon=1e-7,\n            mode='max'\n        )\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(\n                optimizer=optimizer,\n                loss=tf.keras.losses.MeanSquaredError(),\n                metrics=[psnr_denoising]\n            )\n\nmodel.fit(\n                train_ds,\n                validation_data=val_ds,\n                epochs=5,\n                callbacks=[early_stopping_callback, model_checkpoint_callback, reduce_lr_loss]\n            )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"dummy_trainingbest_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\nwith open(\"best_model.tflite\", 'wb') as f:\n    f.write(tflite_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inferrer(image, input_dims=(1, 400, 600, 3)):\n    interpreter = tf.lite.Interpreter(model_path=\"best_model.tflite\")\n    interpreter.allocate_tensors()\n    input_details = interpreter.get_input_details()\n    output_details = interpreter.get_output_details()\n    interpreter.resize_tensor_input(input_details[0]['index'], input_dims)\n\n    input_index = input_details[0][\"index\"]\n    output_index = output_details[0][\"index\"]\n\n    interpreter.allocate_tensors()\n    interpreter.set_tensor(input_index, image)\n\n    interpreter.invoke()\n    output = interpreter.get_tensor(output_index)\n    \n    # Convert output array to image\n    # output_image = (np.squeeze(output, axis=0).clip(0, 1) * 255).astype(np.uint8)\n\n    # img = Image.fromarray(output_image)\n    \n    return output[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob, time\n\nlowlight_test_images_path = \"test/super_resolution/\"\ntest_files = glob.glob(lowlight_test_images_path + \"*.png\")\n\nfor test_file in tqdm.tqdm(test_files, total=len(test_files)):\n    \n        filename = test_file.split(\"/\")[-1]\n        lr_img = cv2.imread(test_file)\n        lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2RGB)\n        print(lr_img.shape)\n        \n        # for resizing specific model data to specific dim.\n        lr_img = get_lowres_image(lr_img, mode=\"super_resolution\")\n        print(lr_img.shape)\n        \n        inputs = img_to_array(lr_img)\n        inputs = np.expand_dims(inputs, axis=0)\n        t = time.time()\n        \n        lr_img_shape = lr_img.shape\n        inferrer_input_dims = (1, lr_img_shape[0], lr_img_shape[1], lr_img_shape[2])\n        enhanced_image = inferrer(inputs, inferrer_input_dims)\n        print(\"Time taken for inference: \", time.time() - t)\n\n        if False:\n            plt.figure()\n            plt.subplot(131)\n            plt.imshow(original_img)\n            \n            plt.subplot(132)\n            plt.imshow(enhanced_image)\n            \n            plt.show()\n        \n        \n        save_file_dir = lowlight_test_images_path.replace('test', 'results')\n        save_file_path = save_file_dir  + filename\n        print(save_file_path, \"save path\")\n        cv2.imwrite(save_file_path, cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2RGB))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_paths = glob.glob(\"results/super_resolution/*.png\")\nfor img_path in img_paths:\n#    n_rows = len(img_paths)\n    img = cv2.imread(img_path)\n    \n    print(img.shape, \"result shape\")\n\n    plt.figure()\n    plt.imshow(img)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/tuvovan/MIRNet-Keras.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2 \n\nimg = cv2.imread('MIRNet-Keras/test/super/Canon_005_LR3.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.resize(img, (400, 260))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(model(np.expand_dims(img, axis=0))[0]/255.0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}